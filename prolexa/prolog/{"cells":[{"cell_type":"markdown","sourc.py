{"cells":[{"cell_type":"markdown","source":["## Mount Google Drive for saving model weights later"],"metadata":{"id":"vc4z-pnllzri"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dM3x5UhDh7Bv","executionInfo":{"status":"ok","timestamp":1680270338165,"user_tz":-60,"elapsed":23918,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}},"outputId":"555e047d-20de-4b69-d261-2d7b21e507da"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Get dataset from github"],"metadata":{"id":"nNfCwbEQMHTL"}},{"cell_type":"code","source":["#!git clone https://github.com/hpfield/ads_dataset_sample.git # 5 classes of the full dataset\n","!git clone https://github.com/hpfield/ads_dataset.git # Comes resized to 224x224"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JwX537lkLILD","executionInfo":{"status":"ok","timestamp":1680270395842,"user_tz":-60,"elapsed":57688,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}},"outputId":"6be52d73-2a46-48d2-dab0-89195f6e9f8d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ads_dataset'...\n","remote: Enumerating objects: 15837, done.\u001b[K\n","remote: Total 15837 (delta 0), reused 0 (delta 0), pack-reused 15837\u001b[K\n","Receiving objects: 100% (15837/15837), 721.26 MiB | 12.82 MiB/s, done.\n","Resolving deltas: 100% (3/3), done.\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gNPeFH42lSKx","executionInfo":{"status":"ok","timestamp":1680270396648,"user_tz":-60,"elapsed":809,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["import os\n","import shutil\n","import random\n","import pandas as pd\n","import cv2\n","import numpy as np\n","from tqdm import tqdm"]},{"cell_type":"markdown","source":["## Resize images in dataset (if not already resized)"],"metadata":{"id":"1piCNga6S3CR"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"H1kuFsEeRt1L","outputId":"6db90f9f-126e-43e8-aded-c3f24accfea5","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1680270396649,"user_tz":-60,"elapsed":13,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-1132c269a70e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get all subfolders of dataset directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/ads_dataset_sample/dataset_sample/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# remove hidden files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ads_dataset_sample/dataset_sample/'"]}],"source":["# get all subfolders of dataset directory\n","base_dir = '/content/ads_dataset_sample/dataset_sample/'\n","folders = os.listdir(base_dir)\n","# remove hidden files\n","folders = [f for f in folders if not f.startswith('.')]\n","destination = '/content/ads_dataset_sample/dataset_sample_resized/'\n","# remove resized folder if it already exists\n","if os.path.exists(destination):\n","    os.system('rm -r /content/ads_dataset_sample/dataset_sample_resized/')\n","\n","# Create resized folder\n","os.makedirs(destination)\n","\n","# loop through all subfolders\n","for folder in tqdm(folders):\n","    # create the subfolder in the resized folder\n","    if not os.path.exists(destination + folder):\n","        os.makedirs(destination + folder)\n","    # get all files in the subfolder\n","    files = os.listdir(base_dir + folder)\n","    # remove hidden files\n","    files = [f for f in files if not f.startswith('.')]\n","    # loop through all files in the subfolder\n","    for file in files:\n","        # read the image\n","        img = cv2.imread(base_dir + folder + '/' + file)\n","        # resize the image\n","        img = cv2.resize(img, (224, 224))\n","        # save the image\n","        cv2.imwrite(destination + folder + '/' + file, img)"]},{"cell_type":"markdown","source":["## Segment the dataset into train, test"],"metadata":{"id":"sTBplkk7L8ip"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"z9p8a23mlSKy","executionInfo":{"status":"ok","timestamp":1680270413173,"user_tz":-60,"elapsed":466,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["\n","# Set the seed for reproducibility\n","random.seed(42)\n","\n","# Set the path to the original dataset\n","original_dataset_dir = '/content/ads_dataset/uob_image_set_resized/'\n","\n","# Set the base directory for the new dataset\n","base_dir = '/content/ads_dataset/YOLOv5_train_test_classification/'\n","\n","# Remove directories if exist\n","if os.path.exists(base_dir):\n","    shutil.rmtree(base_dir)\n","os.mkdir(base_dir)\n","# Create the directories\n","\n","# Create the train directory\n","train_dir = os.path.join(base_dir, 'train')\n","\n","if not os.path.exists(train_dir):\n","    os.mkdir(train_dir)\n","\n","# Create the test directory\n","test_dir = os.path.join(base_dir, 'test')\n","\n","if not os.path.exists(test_dir):\n","    os.mkdir(test_dir)\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"i4i9Lu9RlSKz","executionInfo":{"status":"ok","timestamp":1680270414337,"user_tz":-60,"elapsed":3,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["# Create the directories for each class using the original dataset directory\n","# each folder is it's own class\n","\n","# Get the folder names from the original dataset directory\n","\n","classes = os.listdir(original_dataset_dir)\n","\n","# Remove hidden files\n","classes = [c for c in classes if not c.startswith('.')]\n","\n","# Create the directories for each class in the train and test directories\n","\n","for class_name in classes:\n","    # Create the train directory for the class\n","    train_class_dir = os.path.join(train_dir, class_name)\n","    \n","    if not os.path.exists(train_class_dir):\n","        os.mkdir(train_class_dir)\n","        \n","    # Create the test directory for the class\n","    test_class_dir = os.path.join(test_dir, class_name)\n","    \n","    if not os.path.exists(test_class_dir):\n","        os.mkdir(test_class_dir)\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XbCLHvD5lSKz","executionInfo":{"status":"ok","timestamp":1680270417411,"user_tz":-60,"elapsed":3076,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["# Copy the images into the train and test directories\n","\n","# Get the list of images for each class and store them in a dataframe\n","\n","# Create a dataframe to store the image names and their class\n","dataset = pd.DataFrame(columns=['image_name', 'class'])\n","\n","# Loop through each class\n","for class_name in classes:\n","    # Get the list of images for the class\n","    images = os.listdir(os.path.join(original_dataset_dir, class_name))\n","    for image in images:\n","        # Add the image name and class to the dataframe using pd.concat\n","        dataset = pd.concat([dataset, pd.DataFrame({'image_name': [image], 'class': [class_name]})], ignore_index=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ctjIRAf_lSKz","executionInfo":{"status":"ok","timestamp":1680270419236,"user_tz":-60,"elapsed":1829,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["# Split the dataset into train and test\n","# Use a 80/20 split\n","# Ensure that each class has at least one example in both the train and test sets\n","\n","# Create a dataframe to store the train images\n","train = pd.DataFrame(columns=['image_name', 'class'])\n","\n","# Create a dataframe to store the test images\n","test = pd.DataFrame(columns=['image_name', 'class'])\n","\n","# Loop through each class\n","for class_name in classes:\n","    # Get the list of images for the class\n","    images = dataset[dataset['class'] == class_name]\n","    \n","    # Get the number of images for the class\n","    num_images = len(images)\n","    \n","    # Get the number of images to use for the test set\n","    num_test_images = int(num_images * 0.2)\n","    \n","    # Get the number of images to use for the train set\n","    num_train_images = num_images - num_test_images\n","    \n","    # Get the images to use for the train set\n","    train_images = images.sample(n=num_train_images, random_state=42)\n","    \n","    # Get the images to use for the test set\n","    test_images = images.drop(train_images.index)\n","\n","    if len(test_images) == 0:\n","        # If there are no images in the test set, move one image from the train set to the test set\n","        test_images = train_images.sample(n=1, random_state=42)\n","        train_images = train_images.drop(test_images.index)\n","        \n","    # Add the images to the train and test dataframes\n","    train = pd.concat([train, train_images], ignore_index=True)\n","    test = pd.concat([test, test_images], ignore_index=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"fpPb2PWqlSK0","executionInfo":{"status":"ok","timestamp":1680270421122,"user_tz":-60,"elapsed":1890,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["# Copy the images into the train and test directories\n","\n","# Loop through each class\n","for class_name in classes:\n","    # Get the list of images for the class\n","    train_images = train[train['class'] == class_name]['image_name'].tolist()\n","    test_images = test[test['class'] == class_name]['image_name'].tolist()\n","\n","    # Check if the train_images and test_images lists are empty\n","    if len(train_images) == 0:\n","        print('No train images for class: {}'.format(class_name))\n","\n","    if len(test_images) == 0:\n","        print('No test images for class: {}'.format(class_name))\n","    \n","    # Copy the images into the train and test directories\n","    for image in train_images:\n","        src = os.path.join(original_dataset_dir, class_name, image)\n","        dst = os.path.join(train_dir, class_name, image)\n","        shutil.copyfile(src, dst)\n","        \n","    for image in test_images:\n","        src = os.path.join(original_dataset_dir, class_name, image)\n","        dst = os.path.join(test_dir, class_name, image)\n","        shutil.copyfile(src, dst)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"GWydL8KPlSK0","executionInfo":{"status":"ok","timestamp":1680270421123,"user_tz":-60,"elapsed":5,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[],"source":["# Check if any of the folders in the train and test directories are empty\n","\n","# Loop through each class\n","for class_name in classes:\n","    # Get the list of images for the class\n","    train_images = os.listdir(os.path.join(train_dir, class_name))\n","    test_images = os.listdir(os.path.join(test_dir, class_name))\n","    \n","    # Check if the train and test directories are empty\n","    if len(train_images) == 0:\n","        print('The train directory for the class {} is empty'.format(class_name))\n","    if len(test_images) == 0:\n","        print('The test directory for the class {} is empty'.format(class_name))"]},{"cell_type":"markdown","source":["## Download and run YOLOv5"],"metadata":{"id":"Dqio_iesSwj_"}},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbvMlHd_QwMG","outputId":"303cf988-ec18-443c-dd3b-936c70b02f81","executionInfo":{"status":"ok","timestamp":1680270460294,"user_tz":-60,"elapsed":14998,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 ðŸš€ v7.0-132-ga82132c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.6/78.2 GB disk)\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt  # install\n","\n","import torch\n","import utils\n","display = utils.notebook_init()  # checks"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1NcFxRcFdJ_O","outputId":"f684cdde-a1df-43a3-e297-a1c294d14568","executionInfo":{"status":"ok","timestamp":1680270986094,"user_tz":-60,"elapsed":484274,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, data=/content/ads_dataset/YOLOv5_train_test_classification/, epochs=20, batch_size=64, imgsz=224, nosave=False, cache=ram, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=True, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v7.0-132-ga82132c Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n","2023-03-31 13:48:24.410989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-31 13:48:25.340915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[0, 0]), Normalize(p=1.0, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-cls.pt to yolov5s-cls.pt...\n","100% 10.5M/10.5M [00:01<00:00, 6.75MB/s]\n","\n","Model summary: 149 layers, 6093980 parameters, 6093980 gradients, 12.0 GFLOPs\n","\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 32 weight(decay=0.0), 33 weight(decay=5e-05), 33 bias\n","Image sizes 224 train, 224 test\n","Using 1 dataloader workers\n","Logging results to \u001b[1mruns/train-cls/exp\u001b[0m\n","Starting yolov5s-cls.pt training on /content/ads_dataset/YOLOv5_train_test_classification dataset with 1500 classes for 20 epochs...\n","\n","     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n","      1/20     1.44G         7.3        6.93      0.0107      0.0473: 100% 77/77 [00:22<00:00,  3.42it/s]\n","      2/20      1.7G        6.22        5.88       0.056       0.172: 100% 77/77 [00:23<00:00,  3.30it/s]\n","      3/20      1.7G        4.97         5.2       0.137       0.333: 100% 77/77 [00:22<00:00,  3.49it/s]\n","      4/20      1.7G        4.11        4.48        0.26       0.511: 100% 77/77 [00:23<00:00,  3.32it/s]\n","      5/20      1.7G        3.45        3.87       0.406       0.658: 100% 77/77 [00:21<00:00,  3.52it/s]\n","      6/20      1.7G        2.99        3.63       0.481       0.705: 100% 77/77 [00:22<00:00,  3.36it/s]\n","      7/20      1.7G        2.69        3.56       0.497       0.717: 100% 77/77 [00:22<00:00,  3.42it/s]\n","      8/20      1.7G        2.42        3.43       0.533       0.723: 100% 77/77 [00:22<00:00,  3.48it/s]\n","      9/20      1.7G        2.24        3.21        0.57       0.753: 100% 77/77 [00:22<00:00,  3.35it/s]\n","     10/20      1.7G        2.11        3.33       0.558       0.741: 100% 77/77 [00:21<00:00,  3.55it/s]\n","     11/20      1.7G           2        3.17       0.579       0.759: 100% 77/77 [00:23<00:00,  3.30it/s]\n","     12/20      1.7G        1.93        2.97       0.625       0.783: 100% 77/77 [00:21<00:00,  3.60it/s]\n","     13/20      1.7G        1.89        3.06       0.621       0.772: 100% 77/77 [00:23<00:00,  3.31it/s]\n","     14/20      1.7G        1.81        2.92        0.64       0.797: 100% 77/77 [00:21<00:00,  3.55it/s]\n","     15/20      1.7G        1.76         2.9        0.65       0.801: 100% 77/77 [00:23<00:00,  3.32it/s]\n","     16/20      1.7G        1.71        2.88       0.657       0.795: 100% 77/77 [00:21<00:00,  3.56it/s]\n","     17/20      1.7G        1.65        2.89       0.645       0.795: 100% 77/77 [00:23<00:00,  3.31it/s]\n","     18/20      1.7G        1.64        2.86       0.661       0.804: 100% 77/77 [00:22<00:00,  3.49it/s]\n","     19/20      1.7G        1.61         2.8       0.671       0.806: 100% 77/77 [00:22<00:00,  3.43it/s]\n","     20/20      1.7G        1.57         2.8       0.675       0.802: 100% 77/77 [00:22<00:00,  3.40it/s]\n","\n","Training complete (0.126 hours)\n","Results saved to \u001b[1mruns/train-cls/exp\u001b[0m\n","Predict:         python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source im.jpg\n","Validate:        python classify/val.py --weights runs/train-cls/exp/weights/best.pt --data /content/ads_dataset/YOLOv5_train_test_classification\n","Export:          python export.py --weights runs/train-cls/exp/weights/best.pt --include onnx\n","PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp/weights/best.pt')\n","Visualize:       https://netron.app\n","\n"]}],"source":["# Train YOLOv5s Classification on fashion images\n","!python classify/train.py --model yolov5s-cls.pt --data '/content/ads_dataset/YOLOv5_train_test_classification/' --epochs 20 --img 224 --cache"]},{"cell_type":"markdown","source":["## Copy weights to Drive for later use"],"metadata":{"id":"RcloTGmhkCjU"}},{"cell_type":"code","source":["weights_source = '/content/yolov5/runs/train-cls/exp/weights/best.pt'\n","weights_dest = '/content/drive/MyDrive/Applied_Data_Science/yolov5/classification/weights/classify_224'\n","if not os.path.exists(weights_dest):\n","        os.makedirs(weights_dest)\n","shutil.copy(weights_source, weights_dest)"],"metadata":{"id":"1sXjPfiljEXb","executionInfo":{"status":"aborted","timestamp":1680270396651,"user_tz":-60,"elapsed":10,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run inference in Colab"],"metadata":{"id":"XCmZb9FEknyo"}},{"cell_type":"markdown","source":["To change the colour of the label text, go to classify/predict.py line 147"],"metadata":{"id":"_c0Tyt4LPrMk"}},{"cell_type":"markdown","source":["To update the weights to reflect a new training run, change the exp in the weights argument"],"metadata":{"id":"6I-Cy352RVdL"}},{"cell_type":"code","source":["!python classify/predict.py --weights runs/train-cls/exp/weights/best.pt --source '/content/ads_dataset/YOLOv5_train_test_classification/test/*/*.jpg' --visualize --save-txt"],"metadata":{"id":"XnOS5ysv8FUf","executionInfo":{"status":"aborted","timestamp":1680270396651,"user_tz":-60,"elapsed":10,"user":{"displayName":"Harrison Field","userId":"02417387657116967688"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/ultralytics/yolov5/blob/master/classify/tutorial.ipynb","timestamp":1678802707557}],"collapsed_sections":["1piCNga6S3CR"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}